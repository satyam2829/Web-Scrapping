{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pip install beautifulsoup4\n",
    "### pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to extract social media links from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the website address: https://www.iitm.ac.in/\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "all_hrefs = []\n",
    "\n",
    "url = input(\"Enter the website address: \")\n",
    "\n",
    "if 'https://' not in url:\n",
    "    url = 'https://' + url\n",
    "\n",
    "### create prerender variable\n",
    "prerender = \"http://13.127.9.76/\"\n",
    "prerender_url = prerender + url\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Website\", \"Facebook\", \"LinkedIn\", \"Twitter\", \"Instagram\", \"Youtube\", \"Producthunt\", \n",
    "                           \"Github\", \"Gitlab\", \"bitbucket\"])\n",
    "\n",
    "    \n",
    "try:\n",
    "    r = requests.get(prerender_url, timeout = 10)\n",
    "    if(r.status_code == 500):\n",
    "        r = requests.get(url, timeout = 10)\n",
    "        #print(r.status_code)\n",
    "        \n",
    "except requests.exceptions.RequestException as err:\n",
    "    print(err)\n",
    "        \n",
    "else:\n",
    "    facebook_link = []\n",
    "    linkedin_link = []\n",
    "    twitter_link = []\n",
    "    instagram_link = []\n",
    "    youtube_link = []\n",
    "    github_link = []\n",
    "    gitlab_link = []\n",
    "    producthunt_link = []\n",
    "    bitbucket_link = []\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    all_links = soup.find_all('a', href=True) #only get href\n",
    "    \n",
    "    for links in all_links:\n",
    "        all_hrefs.append(links['href'])\n",
    "    #print(all_hrefs)\n",
    "    \n",
    "    for link in all_hrefs:\n",
    "        if \"facebook.com\" in link:        ### check facebook link\n",
    "            facebook_link.append(link)\n",
    "            \n",
    "        elif \"linkedin.com\" in link:      ### check linkedin link\n",
    "            linkedin_link.append(link)\n",
    "            \n",
    "        elif \"twitter.com\" in link:        ### check twitter link\n",
    "            twitter_link.append(link)\n",
    "            \n",
    "        elif \"instagram.com\" in link:     ### check instagram link\n",
    "            instagram_link.append(link)\n",
    "            \n",
    "        elif \"youtube.com\" in link:       ### check youtube link\n",
    "            youtube_link.append(link)\n",
    "                \n",
    "        elif \"producthunt.com\" in link:   ### check producthunt link\n",
    "            producthunt_link.append(link)\n",
    "                \n",
    "        elif \"github.com\" in link:        ### check github link\n",
    "            github_link.append(link)\n",
    "                \n",
    "        elif \"gitlab.com\" in link:        ### check gitlab link\n",
    "            gitlab_link.append(link)\n",
    "            \n",
    "        elif \"bitbucket.org\" in link:     ### check bitbukcet link\n",
    "            bitbucket_link.append(link)\n",
    "            \n",
    "finally:\n",
    "    social_media_links = {'Website': url,\n",
    "                          'Facebook': facebook_link,\n",
    "                          'LinkedIn': linkedin_link,\n",
    "                          'Twitter': twitter_link,\n",
    "                          'Instagram': instagram_link,\n",
    "                          'Youtube': youtube_link,\n",
    "                          'ProductHunt': producthunt_link,\n",
    "                          'GitHub': github_link,\n",
    "                          'GitLab': gitlab_link,\n",
    "                          'Bitbukcet': bitbucket_link}\n",
    "    \n",
    "    with open('social_media.json', 'w') as json_file:\n",
    "        json.dump(social_media_links, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the extracted social media links from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website: https://www.iitm.ac.in/\n",
      "Facebook: https://www.facebook.com/ReachIITM\n",
      "LinkedIn: https://www.linkedin.com/school/reachiitm/\n",
      "Twitter: https://twitter.com/iitmadras\n",
      "Instagram: https://www.instagram.com/reachiitm/\n",
      "Youtube: https://youtube.com/user/ReachIITM\n",
      "ProductHunt: no link\n",
      "GitHub: no link\n",
      "GitLab: no link\n",
      "Bitbukcet: no link\n"
     ]
    }
   ],
   "source": [
    "for k,v in social_media_links.items():\n",
    "    if(len(v) != 0 and type(v) == list):\n",
    "        print(\"{}: {}\".format(k,v[0]))\n",
    "    elif(len(v) != 0 and type(v) != list):\n",
    "        print(\"{}: {}\".format(k,v))\n",
    "    else:\n",
    "        print(\"{}: {}\".format(k, \"no link\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
